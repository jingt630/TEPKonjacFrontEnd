# ğŸ”§ Backend Fix: Image Extraction with Base64

## ğŸ› The Problem

**Error:** `The filename or extension is too long. (os error 206)`

**Cause:** The `gemini-llm.ts` file was treating base64 data as a file path!

```
Base64 data: "data:image/jpeg;base64,/9j/4AAQSkZJRg..." (100,000+ chars)
                â†“
gemini-llm.ts tries: Deno.readFile("data:image/jpeg;base64,/9j/...")
                â†“
Error: Filename too long! âŒ
```

---

## âœ… Solution (2 Files to Update)

### **File 1: `concept_backend/gemini-llm.ts`**

**Replace the ENTIRE file with this:**

```typescript
import { GoogleGenerativeAI } from "npm:@google/generative-ai";

export class GeminiLLM {
  private genAI: GoogleGenerativeAI;
  private model: any;

  constructor() {
    const apiKey = Deno.env.get("GEMINI_API_KEY");
    if (!apiKey) {
      throw new Error("GEMINI_API_KEY environment variable is not set");
    }
    this.genAI = new GoogleGenerativeAI(apiKey);
    this.model = this.genAI.getGenerativeModel({ model: "gemini-1.5-flash" });
  }

  async executeLLM(prompt: string, imageInput: string): Promise<string> {
    try {
      console.log("ğŸ¤– Calling Gemini AI...");

      let imageData: string;
      let mimeType: string = "image/jpeg";

      // ========== KEY FIX: Check if it's base64 data or file path ==========
      if (imageInput.startsWith("data:")) {
        console.log("ğŸ“Š Using base64 data directly (from database)");

        // Extract mime type and base64 data
        const matches = imageInput.match(/^data:([^;]+);base64,(.+)$/);
        if (!matches) {
          throw new Error("Invalid data URI format");
        }

        mimeType = matches[1];
        imageData = matches[2];

        console.log(`   Mime type: ${mimeType}`);
        console.log(`   Base64 length: ${imageData.length} chars`);
        // âŒ Removed: console.log with actual image data

      } else {
        // It's a file path - read from disk
        console.log(`ğŸ“· Reading image from file: ${imageInput}`);

        const fileBytes = await Deno.readFile(imageInput);
        imageData = btoa(String.fromCharCode(...fileBytes));

        if (imageInput.endsWith(".png")) {
          mimeType = "image/png";
        } else if (imageInput.endsWith(".jpg") || imageInput.endsWith(".jpeg")) {
          mimeType = "image/jpeg";
        } else if (imageInput.endsWith(".webp")) {
          mimeType = "image/webp";
        }

        console.log(`   File size: ${fileBytes.length} bytes`);
        console.log(`   Mime type: ${mimeType}`);
      }
      // ========== END FIX ==========

      const imagePart = {
        inlineData: {
          data: imageData,
          mimeType: mimeType,
        },
      };

      console.log("ğŸ“¤ Sending request to Gemini API...");

      const result = await this.model.generateContent([prompt, imagePart]);
      const response = await result.response;
      const text = response.text();

      console.log("âœ… Gemini API response received");
      console.log(`   Response length: ${text.length} chars`);

      return text;
    } catch (error) {
      console.error("âŒ Error calling Gemini API:", (error as Error).message);
      throw error;
    }
  }
}
```

---

### **File 2: `concept_backend/src/concepts/TextExtraction/TextExtraction.ts`**

**Find this section (around line 192):**
```typescript
console.log(`âœ… Image data retrieved from database (${storedImage.size} bytes)`);

// Prepare image data for AI (with data URI prefix if not already present)
const imageDataForAI = storedImage.imageData.startsWith('data:')
  ? storedImage.imageData
  : `data:${storedImage.mimeType};base64,${storedImage.imageData}`;
```

**Make sure it does NOT log the actual image data:**
```typescript
console.log(`âœ… Image data retrieved from database (${storedImage.size} bytes)`);
// âŒ DO NOT LOG: console.log('Image data:', imageDataForAI)

// Prepare image data for AI (with data URI prefix if not already present)
const imageDataForAI = storedImage.imageData.startsWith('data:')
  ? storedImage.imageData
  : `data:${storedImage.mimeType};base64,${storedImage.imageData}`;

console.log(`ğŸ“ Using default dimensions: 1920x1080`);
// âŒ DO NOT LOG: console.log('Prepared data:', imageDataForAI)
```

---

## ğŸ”„ Restart Backend

```powershell
cd C:\Users\jingy\Downloads\concept_backend

# Stop backend (Ctrl+C)

# Restart
deno run --allow-all server.ts
```

---

## ğŸ§ª Test

1. **Upload a new image**
2. **Extract text**

**Expected console output:**
```
ğŸ¤– Starting Gemini AI text extraction for: ChiikawaPoster.jpg
âœ… Image data retrieved from database (125000 bytes)
ğŸ“ Using default dimensions: 1920x1080
ğŸ“¤ Sending image data to Gemini AI...
ğŸ¤– Calling Gemini AI...
ğŸ“Š Using base64 data directly (from database)
   Mime type: image/jpeg
   Base64 length: 93750 chars
ğŸ“¤ Sending request to Gemini API...
âœ… Gemini API response received
   Response length: 450 chars
âœ… Gemini extraction complete
ğŸ“ Found 5 text blocks
âœ… Created 5 extraction records
```

**No more:**
- âŒ "Filename too long" error
- âŒ Image data printed to console

---

## ğŸ“ What Changed

### In `gemini-llm.ts`:

```typescript
// BEFORE (Broken):
async executeLLM(prompt: string, imagePath: string) {
  const fileBytes = await Deno.readFile(imagePath); // â† Treats everything as file path!
  // ...
}

// AFTER (Fixed):
async executeLLM(prompt: string, imageInput: string) {
  if (imageInput.startsWith("data:")) {
    // It's base64 data - use directly âœ…
    const matches = imageInput.match(/^data:([^;]+);base64,(.+)$/);
    imageData = matches[2];
  } else {
    // It's a file path - read file âœ…
    const fileBytes = await Deno.readFile(imageInput);
    imageData = btoa(String.fromCharCode(...fileBytes));
  }
}
```

---

## âœ… Summary

| Issue | Before | After |
|-------|--------|-------|
| Base64 treated as path | âŒ Yes | âœ… Fixed |
| "Filename too long" error | âŒ Yes | âœ… Gone |
| Console filled with image data | âŒ Yes | âœ… Removed |
| AI extraction works | âŒ No | âœ… Yes! |

---

**Update `gemini-llm.ts` and restart backend!** ğŸš€

The complete fixed file is in `FIXED_gemini-llm.ts` - just copy it to your backend!
